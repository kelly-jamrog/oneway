install.packages("caret")
library(caret)
install.packages("regclass")
library(ggplot2)
library(dplry)
library(dplyr)
# PIMA Diabetes Dataset
library(regclass)
data("PIMA")
##--------------------------------------------------------
## Create training and test datasets
##--------------------------------------------------------
library(caret)
set.seed(1234)
index <- createDataPartition(PIMA$Diabetes, p=0.7, list=FALSE)
train <- PIMA[index,]
test <- PIMA[-index,]
table(train$Diabetes)
table(test$Diabetes)
prop.table(train$Diabetes)
prop.table(table(train$Diabetes))
prob.table(table(test$Diabetes))
prop.table(table(test$Diabetes))
##--------------------------------------------------------
## Develop Model
##--------------------------------------------------------
fit <- glm(Diabetes ~ ., data=train, family=binomial)
summary(fit)
##--------------------------------------------------------
## Predict outcome in training data
##--------------------------------------------------------
train$prob <- predict(fit, train, type="response")
train$pred <- factor(train$prob > .5, levels=c(FALSE, TRUE),
labels=c("No", "Yes"))
# look at results
head(train[c("Diabetes", "prob", "pred")])
# confusion matrix
confusionMatrix(train$pred, train$Diabetes)
install.packages("e1071")
library(e1071)
# confusion matrix
confusionMatrix(train$pred, train$Diabetes)
# confusion matrix (resubstitution)
confusionMatrix(train$pred, train$Diabetes, positive = "Yes")
##--------------------------------------------------------
## ROC Curves
## see https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
##--------------------------------------------------------
library(ROCR)
install.packages("ROCR")
##--------------------------------------------------------
## ROC Curves
## see https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
##--------------------------------------------------------
library(ROCR)
# ROC curve
pred <- prediction(train$prob, train$Diabetes)
perf.roc <- performance(pred, "tpr", "fpr")
plot(perf.roc, main="ROC Curve")
abline(a=0, b= 1)
# Area under the curve
perf.auc <- performance(pred, "auc")
perf.auc@y.values
# Area under the curve
perf.auc <- performance(pred, "auc")
perf.auc@y.values
cost.perf <- performance(pred, "cost")
pred@cutoffs[[1]]
pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# find probability where false negative is weighted 3x more than false positive
# false positive: saying that they do have diabetetes when they dont
# false negative: saying that they don't have diabetes when they do
cost.perf <- performance(pred, "cost", cost.fp = 1, cost.fn = 3)
pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
test$prob <- predict(fit.glm, test, type = "response")
##--------------------------------------------------------
## Develop Model
##--------------------------------------------------------
fit,glm <- glm(Diabetes ~ ., data=train, family=binomial)
##--------------------------------------------------------
## Develop Model
##--------------------------------------------------------
fit.glm <- glm(Diabetes ~ ., data=train, family=binomial)
summary(fit.glm)
test$prob <- predict(fit.glm, test, type = "response")
test$prob <- predict(fit.glm, test, type = "response")
library(caret)
test$prob <- predict(fit.glm, test, type = "response")
library(regclass)
library(e1071)
data("PIMA")
##--------------------------------------------------------
## Create training and test datasets
##--------------------------------------------------------
library(caret)
set.seed(1234)
index <- createDataPartition(PIMA$Diabetes, p=0.7, list=FALSE)
train <- PIMA[index,]
test <- PIMA[-index,]
prop.table(table(train$Diabetes))
prop.table(table(test$Diabetes))
##--------------------------------------------------------
## Develop Model
##--------------------------------------------------------
fit.glm <- glm(Diabetes ~ ., data=train, family=binomial)
summary(fit.glm)
##--------------------------------------------------------
## Predict outcome in training data
##--------------------------------------------------------
train$prob <- predict(fit, train, type="response")
##--------------------------------------------------------
## Predict outcome in training data
##--------------------------------------------------------
train$prob <- predict(fit.glm, train, type="response")
train$pred <- factor(train$prob > .5, levels=c(FALSE, TRUE),
labels=c("No", "Yes"))
# look at results
head(train[c("Diabetes", "prob", "pred")])
# confusion matrix (resubstitution)
# evauate performance using the training data set
confusionMatrix(train$pred, train$Diabetes, positive = "Yes")
##--------------------------------------------------------
## ROC Curves
## see https://hopstat.wordpress.com/2014/12/19/a-small-introduction-to-the-rocr-package/
##--------------------------------------------------------
library(ROCR)
# ROC curve
pred <- prediction(train$prob, train$Diabetes)
perf.roc <- performance(pred, "tpr", "fpr")
plot(perf.roc, main="ROC Curve")
abline(a=0, b= 1)
# Area under the curve
perf.auc <- performance(pred, "auc")
perf.auc@y.values
# Find the probability cut off where sensitivity and specificy
# are as high as possible at the same time
cost.perf <- performance(pred, "cost")
pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
# find probability where false negative is weighted 3x more than false positive
# false positive: saying that they do have diabetetes when they dont
# false negative: saying that they don't have diabetes when they do
cost.perf <- performance(pred, "cost", cost.fp = 1, cost.fn = 3)
pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])]
test$prob <- predict(fit.glm, test, type = "response")
test$pred <- factor(test$prob > .58, levels = c(FALSE, TRUE),
labels = c("No", "Yes"))
# Overall Accuracy
perf.acc <- performance(pred, measure = "acc")
# performance
confusionMatrix(test$pred, test$Diabetes, positive = "Yes")
test$pred <- factor(test$prob > .2, levels = c(FALSE, TRUE),
labels = c("No", "Yes"))
# performance
confusionMatrix(test$pred, test$Diabetes, positive = "Yes")
# enhanced ROC curve
source("enhanced ROC curve.R")
# enhanced ROC curve
source("/Users/kellyjamrog/Desktop/temporary files/enhanced ROC curve.R")
myROC(train$prob, train$Diabetes)
# create training and test dataset
library(caret)
data(iris)
set.seed(1234)
index <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
train <- iris[index,]
test <- iris[-index, ]
# standarize the training data
means <- sapply(train[-5]) # take the training data set, but excluse the 5th var (which is species)
# standarize the training data
means <- sapply(train[-5], mean) # take the training data set, but excluse the 5th var (which is species)
sds <- sapply(train[-5], sd)
sd
sds
# create the standarized data
train_scaled <- data.frame(scale(train[-5], center = means, scale = sds))
train_scaled$Species <- train$Species
test_scaled <- data.frame(scale(test[-5], center = means, scale = sds))
test_scaled$Species <- test$Species
##------------------------------------
## standarize the training data
##------------------------------------
library(class)
# 1st param: training dataset without predictor var (Species)
# 2nd param: test data that you want to classify with predictor var
# 3rd param: actual preductuis from the training data set
# 4th param: how many nearest neighbors to be included
test$pred <- knn(train_scaled[-5], test_scaled[-5], train$Species, k = 5)
library(caret)
# predicited, actual
confusionMatrix(test$pred, test_scaled$Species)
install.packages(c("devtools", "roxygen2"), depend = TRUE)
setwd("~/Documents/Wesleyan Year 4/QAC 358 - Advanced R/05- oneway")
library(ggplot2)
cars <- mpg[c('hwy', 'class', 'year')]
save(cars, file = "cars.rda")
library(oneway)
?oneway
example("oneway")
?plot.oneway
library(oneway)
library(devtools)
spell_check()
mydata <- c(2, 5, 3, 9, 10, 16, 3, 4, 5.5, 7)
# calculate 95% confidence interval assuming normality
t.test(mydata)
n <- length(mydata)
Mean <- mean(mydata)
# take a random sample with replacement
sample(mydata, n, replace = TRUE)
# take a random sample with replacement
sample(mydata, n, replace = TRUE) # gets 10 cases, but can have replacement
# take a random sample with replacement
sample(mydata, n, replace = TRUE) # gets 10 cases, but can have replacement
# take a random sample with replacement
sample(mydata, n, replace = TRUE) # gets 10 cases, but can have replacement
# take a random sample with replacement and get the mean
mean(sample(mydata, n, replace = TRUE))
# take a random sample with replacement and get the mean
mean(sample(mydata, n, replace = TRUE))
# take a random sample with replacement and get the mean
mean(sample(mydata, n, replace = TRUE))
# do this a 1000 times
k = 1000
sampleMeans <- vector(mode = "numeric", k)
hist(sampleMeans, breaks = 20)
for (i in 1:k) {
sampleMeans[i] <- mean(sample(mydata, n, replce = TRUE))
}
hist(sampleMeans, breaks = 20)
sampleMeans <- vector(mode = "numeric", k)
for (i in 1:k) {
sampleMeans[i] <- mean(sample(mydata, n, replce = TRUE))
}
# do this a 1000 times
k = 1000
for (i in 1:k) {
sampleMeans[i] <- mean(sample(mydata, n, replace = TRUE))
}
hist(sampleMeans, breaks = 20)
#bias is the difference of hte mean of the sample means nad the over all mean
bias <- sum(sampleMeans - Mean)/k
bias
#bias corrected estiamte
est <- Mean - bias
abline(v=est, lty=2, col = "blue")
# sort vector of means
sampleMeans <- sampleMeans[order(sampleMeans)]
CI <- sampleMeans[c(round(.025 * k), round(.975 * k))]
CI
abline(v = CI, col = "red")
library(boot)
mydata <- c(2, 5, 3, 9, 10, 16, 3, 4, 5.5, 7)
set.seed(1234)
results <- boot(data = mydata, statistic = Mean, R = 1000)
Mean <- function(data, indicies) {
d <- data[indicies]
mean(d)
}
results <- boot(data = mydata, statistic = Mean, R = 1000)
print(results)
boot.ci(results, type = "perc")
# gives the 95% confidence interval
boot.ci(results, type = c("perc", "bca"))
bs <- function(formula, data, indices) {
d <- data[indices, ] # which rows of the data set are we taking
fit <- lm(formula, data = d)
return(coef(fit))
}
set.seed(1234)
results <- boot(data = mtcars, statistic = bs, R = 1000)
results <- boot(data = mtcars, statistic = bs, R = 1000,
formula = mpg ~ wt + disp)
# index 1 = intercept 2 = wt 3 = dis
print(results, index = 2)
boot.ci(results, type = "bca", index = 2)
# calculate 95% CI for slope on displacement
boot.ci(results, type = "bca", index = 3)
plot(results, index = 2)
library(shiny); runApp('~/Documents/Wesleyan Year 3/QAC368/QAC368 Final Project/Scripts/05- shiny app.R')
install.packages("leaflet")
runApp('~/Documents/Wesleyan Year 3/QAC368/QAC368 Final Project/Scripts/05- shiny app.R')
runApp('~/Documents/Wesleyan Year 3/QAC368/QAC368 Final Project/Shiny App/appK.R')
runApp('~/Documents/Wesleyan Year 3/QAC368/QAC368 Final Project/Shiny App/appK.R')
library(oneway)
?oneway
library(ggplot2)
cars <- mpg[c("hwy", "class", "year")]
save(cars, file = "data/cars.rda")
save(cars, file = "data/cars.rda", compress = "xz")
library(devtools)
use_vignette("introduction_to_oneway")
library(oneway)
install.packages("pkgdown")
library(pkgdown)
build_site*()
build_site
build_site()
build_site()
build_site()
build_site()
library(oneway)
